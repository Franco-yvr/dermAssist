{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport tensorflow as tf\nimport os \nimport cv2\nimport math\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split, cross_validate, cross_val_score\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn import datasets\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50","metadata":{"_uuid":"20064362-cf22-4984-87ff-745f0a39df4e","_cell_guid":"2727829c-d804-4be1-859a-1e78996147ae","collapsed":false,"id":"mvUuysyyjBI4","executionInfo":{"status":"ok","timestamp":1634143967096,"user_tz":420,"elapsed":119,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"execution":{"iopub.status.busy":"2021-10-13T22:39:05.990139Z","iopub.execute_input":"2021-10-13T22:39:05.990754Z","iopub.status.idle":"2021-10-13T22:39:06.127577Z","shell.execute_reply.started":"2021-10-13T22:39:05.990715Z","shell.execute_reply":"2021-10-13T22:39:06.126836Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We obtained the dataset from kaggle at this link:\nhttps://www.kaggle.com/shubhamgoel27/dermnet\n\nWe will try to classify the pictures of 23 skin diseases and aim for the highest accuracy, recall, precision and f1Score. To be clear, we will intake pictures and ouput a class prediction. The goal is to predict the right type of skin disease out of 23 types. \n\nThis task could be useful for patients in developing countries who don't have access to a qualifed doctor due to their geographic location, economic condition, language barriers, lack of trust, etc. Such patient could get a rough opinion from the image classifier, then read potential course of action, solution or precautions about the disease on the internet.","metadata":{"_uuid":"834f92de-4cc0-443f-a61e-9007dc6e2aa1","_cell_guid":"82045b6e-ef69-457b-9d61-c1fd65531a68","id":"LFsebknKjBI4","trusted":true}},{"cell_type":"code","source":"# function to use data folder names to build dataframe\ndef extractInfo(location):\n    arr = []\n    for folders in location.glob(\"*\"):\n        for file in folders.glob(\"*jpg\"):\n            d = {}\n            d[\"disease\"] = folders.name.replace(\"Photos\", \"\")\n            # print(file.name)\n            d[\"file\"] = file.name.replace(\".jpg\", \"\")\n            d[\"image_path\"] = str(location) + \"/\" + folders.name + \"/\" + file.name\n            arr.append(d)     \n    return pd.DataFrame(arr)\n\ntrainLocation = Path('../input/dermnet/train')\ntestLocation = Path('../input/dermnet/test')\n\ndf_train = extractInfo(trainLocation)\ndf_test = extractInfo(testLocation)\n\nprint(df_test[:2])","metadata":{"_uuid":"e38aa399-b3b4-4023-861b-f48998cb5e55","_cell_guid":"0de2e06b-e7af-43f9-a961-ca8aaacc1def","collapsed":false,"id":"qitn9x-ljBI4","executionInfo":{"status":"ok","timestamp":1634144120232,"user_tz":420,"elapsed":292,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"f8db5efb-22f8-41b8-f960-f5a80cd8b829","execution":{"iopub.status.busy":"2021-10-13T22:39:11.859875Z","iopub.execute_input":"2021-10-13T22:39:11.860143Z","iopub.status.idle":"2021-10-13T22:39:12.059038Z","shell.execute_reply.started":"2021-10-13T22:39:11.860116Z","shell.execute_reply":"2021-10-13T22:39:12.058291Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Randomly select a small percentage of available dataset due to small laptop CPU.\n# Given 23 classifications and abundance of data, we select a relatively \n# large test set.This will provide confidence in the test score result\n\n# NOTE: only the fraction of the dataset can be run due to memory constraints in kaggle\n# Use this split for now\ndf_train = df_train.sample(frac=0.075)\ndf_test = df_test.sample(frac=0.29)\n\n# create X_train, X_test\ny_train = df_train[\"disease\"]\nX_train = df_train.drop(columns=[\"disease\"])\n\n# create X_valid, X_valid\n# create a validation set to use especially for confusion matrix\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.5, random_state=123)\n\n# create y_train, y_test\ny_test = df_test[\"disease\"]\nX_test = df_test.drop(columns=[\"disease\"])\n\nprint(\"success\")","metadata":{"_uuid":"638d9c90-2595-4b9f-a89e-c2f60ea3b4e3","_cell_guid":"f3f723fa-c10f-48d0-925c-bf83b2ad518a","collapsed":false,"id":"LxzEh2pKjBI4","executionInfo":{"status":"ok","timestamp":1634144164787,"user_tz":420,"elapsed":124,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"execution":{"iopub.status.busy":"2021-10-13T19:19:41.875457Z","iopub.execute_input":"2021-10-13T19:19:41.875724Z","iopub.status.idle":"2021-10-13T19:19:41.891648Z","shell.execute_reply.started":"2021-10-13T19:19:41.87569Z","shell.execute_reply":"2021-10-13T19:19:41.889505Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The number of images contained in the training set is\", X_train.shape[0])\nprint(\"The number of images contained in the validation set is\", X_valid.shape[0])\nprint(\"The number of images contained in the test set is\", X_test.shape[0])","metadata":{"_uuid":"26c64c7e-7b11-407f-b316-008bcecf35a1","_cell_guid":"780549ab-cd80-425d-accb-d5770931d012","collapsed":false,"id":"DMk_-zoBjBI4","executionInfo":{"status":"ok","timestamp":1634144169775,"user_tz":420,"elapsed":116,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"a010bb94-506b-4224-da1b-908fcf72d10e","execution":{"iopub.status.busy":"2021-10-13T19:19:41.893965Z","iopub.execute_input":"2021-10-13T19:19:41.894257Z","iopub.status.idle":"2021-10-13T19:19:41.900076Z","shell.execute_reply.started":"2021-10-13T19:19:41.894204Z","shell.execute_reply":"2021-10-13T19:19:41.899405Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The distribution of diseases in the traning set is:\\n\", y_train.value_counts())","metadata":{"_uuid":"c81da93a-dbc5-4e32-9856-2694c0c91508","_cell_guid":"b1fe1e3e-b2fc-4261-b59b-75bd6cd5c439","collapsed":false,"id":"aW0Pde1ZjBI5","executionInfo":{"status":"ok","timestamp":1634144177582,"user_tz":420,"elapsed":121,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"41bc588a-37c9-47fa-b0b0-3527b497d498","execution":{"iopub.status.busy":"2021-10-13T19:19:41.90155Z","iopub.execute_input":"2021-10-13T19:19:41.902128Z","iopub.status.idle":"2021-10-13T19:19:41.911848Z","shell.execute_reply.started":"2021-10-13T19:19:41.902078Z","shell.execute_reply":"2021-10-13T19:19:41.911013Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The distribution of diseases in the validation set is:\\n\", y_valid.value_counts())","metadata":{"_uuid":"83115167-3dbc-4452-862a-bfcb7ba9f932","_cell_guid":"98daef79-8b72-48d3-b1b6-8786a9144e46","collapsed":false,"id":"C1jqR15yjBI6","executionInfo":{"status":"ok","timestamp":1634144180731,"user_tz":420,"elapsed":116,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"8f24938e-a3bc-4bef-dae8-7de931fa2413","execution":{"iopub.status.busy":"2021-10-13T19:19:41.913434Z","iopub.execute_input":"2021-10-13T19:19:41.913792Z","iopub.status.idle":"2021-10-13T19:19:41.92078Z","shell.execute_reply.started":"2021-10-13T19:19:41.913759Z","shell.execute_reply":"2021-10-13T19:19:41.919993Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The distribution of diseases in the test set is:\\n\", y_test.value_counts())","metadata":{"_uuid":"b1ad3210-3d42-4af9-a5d7-da96b50831fd","_cell_guid":"b9589338-48e4-4eb2-ada3-f2264c7d4208","collapsed":false,"id":"9wEDzke_jBI6","executionInfo":{"status":"ok","timestamp":1634144184033,"user_tz":420,"elapsed":127,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"5ff999df-ce8b-4fc9-ae2e-f98951787f6b","execution":{"iopub.status.busy":"2021-10-13T19:19:41.922135Z","iopub.execute_input":"2021-10-13T19:19:41.922636Z","iopub.status.idle":"2021-10-13T19:19:41.932249Z","shell.execute_reply.started":"2021-10-13T19:19:41.922603Z","shell.execute_reply":"2021-10-13T19:19:41.931432Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defines some metrics pertaining to images size, made by hand\ndef dimensionAnalysis(array):\n        h = []\n        w = []\n        answer = []\n        for img in array:\n            im = cv2.imread(img)\n            h.append(im.shape[0])\n            w.append(im.shape[1])\n        answer.insert(0, np.mean(h))\n        answer.insert(1, np.mean(w))\n        answer.insert(2, np.min(h))\n        answer.insert(3, np.min(w))\n        answer.insert(4, np.max(h))\n        answer.insert(5, np.max(w))\n        return answer\n\n\ndims = dimensionAnalysis(X_train['image_path'])\nprint(\"The average image height is\", dims[0])\nprint(\"The minimum image height is\", dims[2])\nprint(\"The maximum image height is\", dims[4])\nprint(\"The average image width is\", dims[1])\nprint(\"The minimum image width is\", dims[3])\nprint(\"The maximum image width is\", dims[5])","metadata":{"_uuid":"976f6787-1a69-4b2e-9512-6d0ed01c4e05","_cell_guid":"0a274388-e06f-4dfb-80f4-d5367d39be82","collapsed":false,"id":"xvri01HyjBI6","executionInfo":{"status":"ok","timestamp":1634144217013,"user_tz":420,"elapsed":3221,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"ff361762-c4de-4cd1-9ca9-e2298de349bd","execution":{"iopub.status.busy":"2021-10-13T19:19:41.933682Z","iopub.execute_input":"2021-10-13T19:19:41.934151Z","iopub.status.idle":"2021-10-13T19:19:47.917538Z","shell.execute_reply.started":"2021-10-13T19:19:41.934104Z","shell.execute_reply":"2021-10-13T19:19:47.916748Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the images are generally similar in size and that they are large enough for using more than the 256 x 256 pixel during training. Clearly our computation power is the greatest limit here.","metadata":{"_uuid":"09b7ef10-19d1-4801-94bd-41b2cb412f5f","_cell_guid":"efbd24ad-3ce0-472c-8014-04bcbe10aa07","id":"Fd8L6E2bjBI6","trusted":true}},{"cell_type":"markdown","source":"A pipeline is not necessary in our use case, but we have much processing to do...","metadata":{"_uuid":"8a7b20e7-a86b-4f97-97a4-8df6799d22db","_cell_guid":"e9cf1a15-c92e-426a-89ac-3482de83594d","id":"gCILXipdjBI6","trusted":true}},{"cell_type":"code","source":"# read X_train images from the image directory. \nX_train = np.array([img_to_array(\n                    load_img(img, target_size=(256,256))\n                    ) for img in X_train['image_path'].values.tolist()])\n\nX_train.shape","metadata":{"_uuid":"8a451a79-2a7d-4616-a994-cd5e3130eab9","_cell_guid":"1c852d86-0cda-4bde-89fd-1821c9685fb3","collapsed":false,"id":"PnDz9DDgjBI6","executionInfo":{"status":"ok","timestamp":1634144253668,"user_tz":420,"elapsed":3906,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"d363ae77-1acd-4c92-ab36-b1695d2a21a9","execution":{"iopub.status.busy":"2021-10-13T19:19:47.918781Z","iopub.execute_input":"2021-10-13T19:19:47.919506Z","iopub.status.idle":"2021-10-13T19:19:51.479223Z","shell.execute_reply.started":"2021-10-13T19:19:47.919468Z","shell.execute_reply":"2021-10-13T19:19:51.478558Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read X_valid images from the image directory. \nX_valid = np.array([img_to_array(\n                    load_img(img, target_size=(256,256))\n                    ) for img in X_valid['image_path'].values.tolist()])\n\nX_valid.shape","metadata":{"_uuid":"500d9b12-f29e-42a1-a57a-725f4f445135","_cell_guid":"31fbccb5-7670-4a57-9e18-fb63f2879802","collapsed":false,"id":"DUWn0ynHjBI6","executionInfo":{"status":"ok","timestamp":1634144261963,"user_tz":420,"elapsed":3684,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"5fb6a3bb-3ddb-40a8-b59a-ead86f9e6557","execution":{"iopub.status.busy":"2021-10-13T19:19:51.480515Z","iopub.execute_input":"2021-10-13T19:19:51.48079Z","iopub.status.idle":"2021-10-13T19:19:57.229911Z","shell.execute_reply.started":"2021-10-13T19:19:51.480756Z","shell.execute_reply":"2021-10-13T19:19:57.229216Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read X_test images from the image directory. \nX_test = np.array([img_to_array(\n                    load_img(img, target_size=(256,256))\n                    ) for img in X_test['image_path'].values.tolist()])\n\nX_test.shape","metadata":{"_uuid":"c0d56933-e6ce-4394-9c69-7ee2d3ddb1eb","_cell_guid":"8b684c5b-182f-47de-a4c9-d032354e34ea","collapsed":false,"id":"9BaQSwRrjBI7","executionInfo":{"status":"ok","timestamp":1634144274418,"user_tz":420,"elapsed":3099,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"e2c6c5d0-6940-4d11-d475-0b50f5e8fe69","execution":{"iopub.status.busy":"2021-10-13T19:19:57.231306Z","iopub.execute_input":"2021-10-13T19:19:57.231558Z","iopub.status.idle":"2021-10-13T19:20:07.661797Z","shell.execute_reply.started":"2021-10-13T19:19:57.231525Z","shell.execute_reply":"2021-10-13T19:20:07.661041Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale image data\nX_train = X_train.astype('float32')/255.0 \nX_valid = X_valid.astype('float32')/255.0 \nX_test = X_test.astype('float32')/255.0","metadata":{"_uuid":"1cefba53-fe43-4942-800e-02b8bcc1c4f4","_cell_guid":"1fb4bfa9-3202-4373-869a-44cf7ee2b7af","collapsed":false,"id":"5Ab_XYPWjBI7","executionInfo":{"status":"ok","timestamp":1634144276129,"user_tz":420,"elapsed":594,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"execution":{"iopub.status.busy":"2021-10-13T19:20:07.664987Z","iopub.execute_input":"2021-10-13T19:20:07.665207Z","iopub.status.idle":"2021-10-13T19:20:08.500169Z","shell.execute_reply.started":"2021-10-13T19:20:07.665183Z","shell.execute_reply":"2021-10-13T19:20:08.499426Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create feature extractor featuring transfer learning with  imagenet\nbase_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\nfeature_extractor = Model(inputs=base_inception.input, outputs=GlobalAveragePooling2D()(base_inception.output))\n\n# transform training and test datasets\nX_train = feature_extractor.predict(X_train)\nX_valid = feature_extractor.predict(X_valid)\nX_test = feature_extractor.predict(X_test)","metadata":{"_uuid":"06e20099-8d79-472b-8be9-04c16e409c8e","_cell_guid":"5a9f20f8-3636-4e63-b424-1c21f04a2ffb","collapsed":false,"id":"bZ_ieL1djBI7","executionInfo":{"status":"ok","timestamp":1634144338108,"user_tz":420,"elapsed":55222,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"e165fdc7-1bb1-4ae4-afae-e13c0196ce14","execution":{"iopub.status.busy":"2021-10-13T19:20:08.501372Z","iopub.execute_input":"2021-10-13T19:20:08.502216Z","iopub.status.idle":"2021-10-13T19:20:17.473923Z","shell.execute_reply.started":"2021-10-13T19:20:08.502178Z","shell.execute_reply":"2021-10-13T19:20:17.473106Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validate initial results\ndef cross_validate_std(*args, **kwargs):\n    \"\"\"Like cross_validate, except also gives the standard deviation of the score\"\"\"\n    res = pd.DataFrame(cross_validate(*args, **kwargs))\n    res_mean = res.mean()\n\n    res_mean[\"std_test_score\"] = res[\"test_score\"].std()\n    if \"train_score\" in res:\n        res_mean[\"std_train_score\"] = res[\"train_score\"].std()\n    return res_mean","metadata":{"_uuid":"026f90a0-ee70-4adf-91f2-1292532ae837","_cell_guid":"84ebbc08-d82b-41d4-aec9-e9da04d5f531","collapsed":false,"id":"1ASc8PqyjBI7","executionInfo":{"status":"ok","timestamp":1634144348363,"user_tz":420,"elapsed":121,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"execution":{"iopub.status.busy":"2021-10-13T19:20:17.479731Z","iopub.execute_input":"2021-10-13T19:20:17.480107Z","iopub.status.idle":"2021-10-13T19:20:17.49596Z","shell.execute_reply.started":"2021-10-13T19:20:17.480071Z","shell.execute_reply":"2021-10-13T19:20:17.494803Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# running dummy classifyer as benchmark\ndc = DummyClassifier(strategy='prior')\ndc.fit(X_train, y_train)\nscore = dc.score(X_train, y_train)\nprint(\"Dummy classifier scores\", score)","metadata":{"_uuid":"a77a2d89-63d9-4f58-b431-d285e81b719c","_cell_guid":"6dfb7a49-66e1-4ee9-8750-41197b47cc5d","collapsed":false,"id":"T-Gn5_sqjBI7","executionInfo":{"status":"ok","timestamp":1634144360772,"user_tz":420,"elapsed":116,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"outputId":"8126b2ca-d66f-42ab-b3b2-522db50a0beb","execution":{"iopub.status.busy":"2021-10-13T19:20:17.501968Z","iopub.execute_input":"2021-10-13T19:20:17.502255Z","iopub.status.idle":"2021-10-13T19:20:17.519928Z","shell.execute_reply.started":"2021-10-13T19:20:17.502208Z","shell.execute_reply":"2021-10-13T19:20:17.519118Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a logistic regresion object\nlr = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000)","metadata":{"_uuid":"5ef9c52b-0ffd-4073-8d8e-54b8ecf7bfd5","_cell_guid":"1a50728c-f880-48c4-9c01-f820731b0561","collapsed":false,"id":"IV4byGtljBI7","executionInfo":{"status":"ok","timestamp":1634144364746,"user_tz":420,"elapsed":258,"user":{"displayName":"Francois C","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02357137708940839927"}},"execution":{"iopub.status.busy":"2021-10-13T19:20:17.522002Z","iopub.execute_input":"2021-10-13T19:20:17.522637Z","iopub.status.idle":"2021-10-13T19:20:17.536364Z","shell.execute_reply.started":"2021-10-13T19:20:17.522591Z","shell.execute_reply":"2021-10-13T19:20:17.530942Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scoring with cross validation standard deviation\nlrScore = cross_validate_std(lr, X_train, y_train, cv=10, return_train_score=True)\nprint(\"Logistic regression scores are:\\n\", lrScore)","metadata":{"_uuid":"ce7d28ae-da95-4387-bb80-78e33ef36dca","_cell_guid":"cc7a608d-6630-4942-b5af-f1024b989bcb","collapsed":false,"id":"g4Iq-KehjBI7","outputId":"fe2d60ed-73d6-49f0-b465-a631299ac02e","execution":{"iopub.status.busy":"2021-10-13T19:20:17.548513Z","iopub.execute_input":"2021-10-13T19:20:17.548915Z","iopub.status.idle":"2021-10-13T19:21:48.429994Z","shell.execute_reply.started":"2021-10-13T19:20:17.54888Z","shell.execute_reply":"2021-10-13T19:21:48.427316Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We obtain very poor accuracy score, likely because we are training the models with only ~450 picture split in 23 classes. This is the best we can do for free on kaggle\n\nGiven the very low score, the standard deviation is very high. This higlights the fact that our training set has only 5-10 pictures per disease while we demand cross validation folds of 10. That is very few picures to train and score on!","metadata":{"_uuid":"d351d62c-d77f-4116-aead-fcb52baf15a3","_cell_guid":"07d31d4f-8863-420e-9cae-005d8b14418d","id":"CPq7zkFtjBI8","trusted":true}},{"cell_type":"code","source":"classList = [\"Nail Fungus and other Nail Disease\",\n\"Tinea Ringworm Candidiasis and other Fungal Infections\",\n\"Eczema\",\n\"Psoriasis pictures Lichen Planus and related diseases\",\n\"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\",\n\"Warts Molluscum and other Viral Infections\",\n\"Seborrheic Keratoses and other Benign Tumors\",\n\"Acne and Rosacea\",\n\"Light Diseases and Disorders of Pigmentation\",\n\"Bullous Disease\",\n\"Melanoma Skin Cancer Nevi and Moles\",\"Exanthems and Drug Eruptions\",\n\"Vasculitis\",\n\"Scabies Lyme Disease and other Infestations and Bites\",\n\"Atopic Dermatitis\",\n\"Vascular Tumors\",\n\"Lupus and other Connective Tissue diseases\",\n\"Cellulitis Impetigo and other Bacterial Infections\",\n\"Systemic Disease\",\n\"Hair Loss  Alopecia and other Hair Diseases\",\n\"Herpes HPV and other STDs\",\n\"Poison Ivy  and other Contact Dermatitis\",\n\"Urticaria Hives\"]\n\n# Calculate logistic regression prediction for confusion matrix\nlr2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000)\nlr2.fit(X_train, y_train)\ny_pred = lr2.predict(X_valid)\nlr2_matrix = confusion_matrix(y_valid, y_pred,labels=classList)\nprint(lr2_matrix)","metadata":{"_uuid":"ff6b4775-b3f1-44ca-8f8a-16d32908c214","_cell_guid":"627adbc2-cc4c-4a0e-9db3-bca2aa7b90dc","collapsed":false,"id":"XKQmuIrLjBI8","execution":{"iopub.status.busy":"2021-10-13T19:21:48.434967Z","iopub.execute_input":"2021-10-13T19:21:48.435283Z","iopub.status.idle":"2021-10-13T19:21:59.115152Z","shell.execute_reply.started":"2021-10-13T19:21:48.435245Z","shell.execute_reply":"2021-10-13T19:21:59.114364Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The multiclass confusion matrix does a really good job showing where the model does better and worse. As expected, the model does a poor job in the lower right, on classes featuring 5-10 pictures for training.","metadata":{"_uuid":"44a02783-3b33-45e3-9a1c-38c7f36bab89","_cell_guid":"1c9c96b7-5aa7-4d74-850b-ba1fba73c52d","id":"iEg93qCtjBI8","trusted":true}},{"cell_type":"code","source":"# inspired by https://www.youtube.com/watch?v=HBi-P5j0Kec\n# inspired by https://stats.stackexchange.com/questions/51296/\n# how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\ndef averageRecall(m):\n    pred = np.diag(m)\n    total = np.sum(m, axis = 0)\n    arr = []\n    i=0\n    for tp in pred:\n        prec = tp / total[i]\n        if (math.isnan(prec)):\n            prec = 0\n        arr = np.append(arr,prec)\n        i+=1\n    return np.mean(arr)\n\ndef averagePrecision(m):\n    pred = np.diag(m)\n    total = np.sum(m, axis = 1)\n    arr = []\n    i=0\n    for tp in pred:\n        recall = tp / total[i]\n        if (math.isnan(recall)):\n            recall = 0\n        arr = np.append(arr,recall)\n        i+=1\n    return np.mean(arr)\n\ndef f1Score(precision, recall):\n    return ((2*precision*recall) / (precision + recall))\n        \nlrRecall = averageRecall(lr2_matrix)\nprint(\"The lr2 recall score is\", lrRecall)\n\nlrPrecision = averagePrecision(lr2_matrix)\nprint(\"The lr2 precision score is\", lrPrecision)\n\nlrF1Score = f1Score(lrPrecision,lrRecall)\nprint(\"The lr2 F1 score is\", lrF1Score)","metadata":{"_uuid":"87ff32e9-4773-48c1-a617-4b8e88e461ab","_cell_guid":"8be943e7-a050-46e4-bfde-6b2455ba1474","collapsed":false,"id":"ISdGTFpejBI8","outputId":"1f36973f-24d6-4c11-9cbd-f47f92e1ca3b","execution":{"iopub.status.busy":"2021-10-13T19:21:59.119631Z","iopub.execute_input":"2021-10-13T19:21:59.121813Z","iopub.status.idle":"2021-10-13T19:21:59.147897Z","shell.execute_reply.started":"2021-10-13T19:21:59.121766Z","shell.execute_reply":"2021-10-13T19:21:59.146764Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The recall, precision and f1 score shows the reality of training the model with too few pictures due to our memory constraint","metadata":{"_uuid":"8497e9a9-ca69-4eef-81df-3a9014c919bf","_cell_guid":"01ac1942-07c5-46f7-80da-a3eb25c177ac","id":"BCJjPfEsjBI8","trusted":true}},{"cell_type":"code","source":"# Evaluate model on the test set\nfinal_lr_score = lr2.score(X_test, y_test)\nprint(\"The final logistic regression score is\",final_lr_score )","metadata":{"_uuid":"068b6d38-9fec-4bb2-865a-c6f4a2830bcf","_cell_guid":"ebb151be-e6e8-458d-988d-58924024f31e","collapsed":false,"id":"h-gZvr4qjBI8","outputId":"ec149d20-4ec9-4ede-e787-33b8b1354237","execution":{"iopub.status.busy":"2021-10-13T19:21:59.175458Z","iopub.execute_input":"2021-10-13T19:21:59.176167Z","iopub.status.idle":"2021-10-13T19:21:59.200034Z","shell.execute_reply.started":"2021-10-13T19:21:59.17613Z","shell.execute_reply":"2021-10-13T19:21:59.199336Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As mentioned before, our laptop CPU restricts us to train both models with a small number of pictures(~500) divided by 23 classes. The accuracy is predictably low. \n\nGiven that scoring is less demanding than than training, we were able to test the final model with a larger number of pictures(~1000) to provide more accuracy. However, it is still a relatively low amount given there are 23 classes. \n\nTo conclude, we ackowledge the poor accuracy and the relatively poor level of confidence due to our weak CPU. Next, we would like to learn how to train a model by exposing it to successive batches of images or by using some online GPU!!!","metadata":{"_uuid":"8824c65a-2bf2-4050-b08a-a2dc41a3dbfa","_cell_guid":"f7cafdec-9669-4ab6-9170-7a70bf768a9f","id":"u6S4U3sYjBI9","trusted":true}}]}